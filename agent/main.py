import logging
import asyncio
import base64
import os
import time
from datetime import datetime
from pyexpat import model
from dotenv import load_dotenv
from livekit import api
# from google.genai import types  # Commented out - web search disabled

from livekit.agents import (
    Agent,
    AgentSession,
    JobContext,
    RoomInputOptions,
    WorkerOptions,
    cli,
    get_job_context,
)
from livekit.agents.llm import ImageContent
from livekit.plugins import google, noise_cancellation

logger = logging.getLogger("vision-assistant")

load_dotenv()


class VisionAssistant(Agent):
    def __init__(self) -> None:
        self._tasks = []
        self._egress_id = None
        self._recording_enabled = os.getenv("ENABLE_RECORDING", "false").lower() == "true"
        self._session_id = datetime.now().strftime("%Y%m%d_%H%M%S")
        super().__init__(
                        instructions="""
You are a warm, playful AI friend helping young children (ages 3-8) through natural conversation and visual observation.

**Your Role:**
You're like a friendly helper who loves to play and learn with children. You can see what they're doing through your camera eyes, and you talk with them using your voice. Your job is to make every child feel special, encouraged, and excited to show you things!

**What You Can See:**
- The child and what they're doing
- Toys, drawings, or objects they show you
- Their facial expressions and movements
- Books, pictures, or anything they point to
- The room and environment around them

**How to Talk with Children:**
- Use SIMPLE words (ages 3-8 level) - no big complicated words
- Be SUPER enthusiastic and encouraging - celebrate everything!
- Show genuine interest in what they're doing
- Ask ONE simple question at a time
- Give lots of positive feedback: "That's amazing!", "Wow!", "Great job!"
- Use a playful, friendly tone with your Aoede voice
- Be patient - children need time to think and respond
- Make them feel proud of what they show you

**Examples of Great Things to Say:**
- "Wow! I can see you have something special! What is it?"
- "That looks so cool! Can you tell me about it?"
- "You're doing such a great job! I love watching you!"
- "Ooh, what color is that? It's so pretty!"
- "That's amazing! Can you show me more?"
- "You're so creative! Tell me about what you made!"

**What NOT to Do:**
- Don't use hard words or long sentences
- Don't sound like a teacher or doctor
- Don't ask too many questions at once
- Don't correct them harshly if they're wrong
- Don't talk when someone else (parent/guardian) is talking
- Don't sound bored or uninterested

**Important Reminders:**
- This is for child assessment, but it should feel like PLAY, not a test
- Describe what you actually see - be accurate
- If a child is shy, be extra gentle and encouraging
- Match their energy - if they're excited, be excited too!
- If they're quiet, be calm and patient
- Make every interaction feel like fun time with a friend!

**Your Super Powers:**
- You can see them through the camera (but make it sound magical, like "I can see you!")
- You understand when they're happy, sad, or excited (affective dialog)
- You know when to listen and when to talk (proactive audio)
- You wait for them to finish talking before you respond (turn detection)

Remember: You're here to make children feel AMAZING and CONFIDENT while you observe and engage with them naturally!
""",
            llm=google.beta.realtime.RealtimeModel(
                model="gemini-2.5-flash-native-audio-preview-09-2025",
                voice="Aoede",
                temperature=0.9,
                # _gemini_tools=[types.GoogleSearch()],  # Commented out - web search disabled
            ),
        )

    async def on_enter(self):
        logger.info(f"üé¨ Agent entering room - Session: {self._session_id}")
        
        # Start recording in background (non-blocking)
        if self._recording_enabled:
            recording_task = asyncio.create_task(self._start_recording_safe())
            self._tasks.append(recording_task)
            recording_task.add_done_callback(lambda t: self._tasks.remove(t))
        else:
            logger.info("üìπ Recording disabled (ENABLE_RECORDING=false)")
        
        def _image_received_handler(reader, participant_identity):
            task = asyncio.create_task(
                self._image_received(reader, participant_identity)
            )
            self._tasks.append(task)
            task.add_done_callback(lambda t: self._tasks.remove(t))
            
        get_job_context().room.register_byte_stream_handler("test", _image_received_handler)

        self.session.generate_reply(
            instructions="Greet the child warmly! Say hello in a friendly, playful way and tell them you're excited to see them and play together!"
        )
    
    async def _start_recording_safe(self):
        """
        Start room recording with LiveKit Egress.
        - Stores on LiveKit Cloud (temporary 48h) OR AWS S3 (if configured)
        - Non-blocking: runs in background
        - Full error handling: never crashes the agent
        """
        room_name = get_job_context().room.name
        start_time = time.time()
        
        try:
            logger.info(f"üìπ Starting recording for room: {room_name}")
            
            # Timeout protection - don't wait forever
            async with asyncio.timeout(5.0):
                # Create egress client
                egress_client = api.EgressService(
                    api_url=os.getenv("LIVEKIT_URL"),
                    api_key=os.getenv("LIVEKIT_API_KEY"),
                    api_secret=os.getenv("LIVEKIT_API_SECRET"),
                )
                
                # Check if S3 is configured (optional for later)
                use_s3 = (
                    os.getenv("AWS_ACCESS_KEY") and 
                    os.getenv("AWS_SECRET_KEY") and 
                    os.getenv("AWS_BUCKET_NAME")
                )
                
                # Build request
                if use_s3:
                    logger.info("‚òÅÔ∏è Using AWS S3 storage")
                    request = api.RoomCompositeEgressRequest(
                        room_name=room_name,
                        layout="speaker",
                        file=api.EncodedFileOutput(
                            file_type=api.EncodedFileType.MP4,
                            filepath=f"sessions/{self._session_id}/{room_name}.mp4",
                            s3=api.S3Upload(
                                access_key=os.getenv("AWS_ACCESS_KEY"),
                                secret=os.getenv("AWS_SECRET_KEY"),
                                region=os.getenv("AWS_REGION", "us-east-1"),
                                bucket=os.getenv("AWS_BUCKET_NAME"),
                            )
                        )
                    )
                else:
                    logger.info("‚è±Ô∏è Using LiveKit Cloud temporary storage (48h retention)")
                    request = api.RoomCompositeEgressRequest(
                        room_name=room_name,
                        layout="speaker",
                        file=api.EncodedFileOutput(
                            file_type=api.EncodedFileType.MP4,
                            filepath=f"sessions/{self._session_id}/{room_name}.mp4"
                        )
                    )
                
                # Start the recording
                info = await egress_client.start_room_composite_egress(request)
                self._egress_id = info.egress_id
                
                duration = time.time() - start_time
                logger.info(f"‚úÖ Recording started successfully in {duration:.2f}s")
                logger.info(f"   üìä Egress ID: {self._egress_id}")
                logger.info(f"   üìÅ Filepath: sessions/{self._session_id}/{room_name}.mp4")
                
                if not use_s3:
                    logger.warning("‚ö†Ô∏è Using temporary storage - file will be deleted after 48h")
                
        except asyncio.TimeoutError:
            duration = time.time() - start_time
            logger.warning(f"‚ö†Ô∏è Recording timeout after {duration:.2f}s - continuing without recording")
            self._egress_id = None
            
        except Exception as e:
            duration = time.time() - start_time
            logger.error(f"‚ùå Recording failed after {duration:.2f}s: {e}")
            logger.error(f"   Agent will continue normally without recording")
            self._egress_id = None
    
    async def _image_received(self, reader, participant_identity):
        logger.info("Received image from %s: '%s'", participant_identity, reader.info.name)
        try:
            image_bytes = bytes()
            async for chunk in reader:
                image_bytes += chunk

            chat_ctx = self.chat_ctx.copy()
            chat_ctx.add_message(
                role="user",
                content=[
                    ImageContent(
                        image=f"data:image/png;base64,{base64.b64encode(image_bytes).decode('utf-8')}"
                    )
                ],
            )
            await self.update_chat_ctx(chat_ctx)
            print("Image received", self.chat_ctx.copy().to_dict(exclude_image=False))
        except Exception as e:
            logger.error("Error processing image: %s", e)


async def entrypoint(ctx: JobContext):
    await ctx.connect()
    
    session = AgentSession()
    await session.start(
        agent=VisionAssistant(),
        room=ctx.room,
        room_input_options=RoomInputOptions(
            video_enabled=True,
            noise_cancellation=noise_cancellation.BVC(),
        ),
    )


if __name__ == "__main__":
    cli.run_app(WorkerOptions(entrypoint_fnc=entrypoint))